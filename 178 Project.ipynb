{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:<br>\n",
    "Joshua Cao<br>\n",
    "Anthony Luu<br>\n",
    "Winfield Zhang<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final project for CS178 intro to machine learning. We were given 100,000 inputs and outputs, along with 100,000 test inputs without the outputs. The goal was to submit out predictions on the test input and achieve the best possible accuracy. \n",
    "<br><br>\n",
    "We primarily used sklearn, although we did experiment with tensorflow and keras. We also used our professor's package, mltools.\n",
    "<br><br>\n",
    "We tested a lot of different classifiers, and averaged the predictions of the best performing ones. We were able to reach 76% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import mltools as ml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neural_network\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"7\">Helper functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_learner(lr):\n",
    "    print(\"training\")\n",
    "    print(lr.score(Xtr, Ytr))\n",
    "    p_tr = lr.predict(Xtr)\n",
    "    print(sklearn.metrics.roc_auc_score(Ytr, lr.predict_proba(Xtr)[:,1]))\n",
    "    print(classification_report(Ytr, p_tr))\n",
    "\n",
    "    print(\"validation\")\n",
    "    print(lr.score(Xva, Yva))\n",
    "    p_va = lr.predict(Xva)\n",
    "    print(sklearn.metrics.roc_auc_score(Yva, lr.predict_proba(Xva)[:,1]))\n",
    "    print(classification_report(Yva, p_va))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, lr):\n",
    "#     p_tr = lr.predict_proba(Xtr)\n",
    "#     f = open(\"predictions_five/\" + filename + \"_tr.txt\", \"w\")\n",
    "#     for i in range(len(p_tr)):\n",
    "#         f.write(str(p_tr[i][1]) + \"\\n\")\n",
    "#     f.close()\n",
    "    \n",
    "    p_va = lr.predict_proba(Xva)\n",
    "    f = open(\"predictions_five/\" + filename + \"_va.txt\", \"w\")\n",
    "    for i in range(len(p_va)):\n",
    "        f.write(str(p_va[i][1]) + \"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    p_te = lr.predict_proba(Xtest)\n",
    "    f = open(\"predictions_five/\" + filename + \"_te.txt\", \"w\")\n",
    "    for i in range(len(p_te)):\n",
    "        f.write(str(p_te[i][1]) + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Data Preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5000e+02 2.3300e+02 2.4308e+02 2.3454e+02 2.5780e+03 2.3100e+02\n",
      "  0.0000e+00 1.6742e+01 5.5478e+00 6.0934e-01 2.7805e+00 2.2254e+00\n",
      "  3.6493e+00 0.0000e+00]\n",
      " [2.3850e+02 2.2900e+02 2.4302e+02 2.3219e+02 4.3980e+03 4.6700e+02\n",
      "  0.0000e+00 3.2346e+00 6.1774e+00 1.7202e+00 3.1890e+00 2.2173e+00\n",
      "  3.0515e+00 0.0000e+00]\n",
      " [2.5000e+02 2.2600e+02 2.4070e+02 2.3199e+02 8.5080e+03 2.4850e+03\n",
      "  0.0000e+00 1.4621e+00 7.1734e+00 2.1631e+00 2.3984e+00 1.2261e+00\n",
      "  1.7826e+00 0.0000e+00]\n",
      " [2.4500e+02 2.4100e+02 2.4818e+02 2.4818e+02 6.1100e+02 0.0000e+00\n",
      "  0.0000e+00 5.4439e+00 3.4458e+00 0.0000e+00 3.3276e+00 1.9390e+00\n",
      "  2.0000e+01 0.0000e+00]\n",
      " [2.5100e+02 2.2250e+02 2.3766e+02 2.2936e+02 1.6150e+03 6.6500e+02\n",
      "  0.0000e+00 1.6030e+00 8.3773e+00 3.4329e+00 5.2864e+00 2.4057e+00\n",
      "  2.8455e+00 0.0000e+00]\n",
      " [2.2650e+02 2.0650e+02 2.2734e+02 2.1308e+02 1.9090e+03 1.3950e+03\n",
      "  6.3200e+02 1.2247e+00 1.2494e+01 8.5875e+00 4.3209e+00 5.1717e+00\n",
      "  1.9251e+00 1.4000e+00]\n",
      " [2.4200e+02 2.2000e+02 2.3727e+02 2.2000e+02 1.3273e+04 6.2380e+03\n",
      "  5.0000e+00 1.6191e+00 8.9106e+00 3.2198e+00 3.3464e+00 2.3880e+00\n",
      "  2.0946e+00 0.0000e+00]\n",
      " [2.2500e+02 2.2000e+02 2.3652e+02 2.2000e+02 2.1420e+03 1.0840e+03\n",
      "  7.0000e+00 1.6800e+00 1.0312e+01 3.7206e+00 3.6147e+00 2.5708e+00\n",
      "  1.2907e+00 2.0000e+01]\n",
      " [2.1900e+02 2.0750e+02 2.3274e+02 2.1463e+02 1.0150e+03 5.2200e+02\n",
      "  3.3300e+02 7.3679e+00 1.5130e+01 7.2136e+00 4.1779e+00 2.7187e+00\n",
      "  1.5921e+00 4.1900e+01]\n",
      " [2.4700e+02 2.3200e+02 2.4394e+02 2.3436e+02 7.8620e+03 2.8200e+02\n",
      "  0.0000e+00 1.6405e+00 5.0836e+00 8.9961e-01 2.6219e+00 1.6354e+00\n",
      "  3.5320e+01 0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.genfromtxt('data/X_train.txt',delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt',delimiter=None)\n",
    "\n",
    "Xtest = np.genfromtxt(\"data/X_test.txt\", delimiter=None)\n",
    "\n",
    "np.random.seed(0)\n",
    "X,Y = ml.shuffleData(X,Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">normalize</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmax = np.max(X, axis=0)\n",
    "Xmin = np.min(X, axis=0)\n",
    "X = (X - Xmin) / (Xmax - Xmin)\n",
    "\n",
    "Xmax = np.max(Xtest, axis=0)\n",
    "Xmin = np.min(Xtest, axis=0)\n",
    "Xtest = (Xtest - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">split data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "Xtr = X[0:50000]\n",
    "Ytr = Y[0:50000]\n",
    "Xva = X[50000:100000]\n",
    "Yva = Y[50000:100000]\n",
    "\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Under sample class 0</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2\">This works well only for a few of the classifiers</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34074, 14)\n",
      "(34074,)\n"
     ]
    }
   ],
   "source": [
    "mask = Ytr == 0\n",
    "Xmask0 = Xtr[mask,:]\n",
    "Xmask1 = Xtr[~mask,:]\n",
    "    \n",
    "len_mask1 = len(Xmask1)\n",
    "ones = np.asarray([1 for _ in range(len_mask1)])\n",
    "zeros = np.asarray([0 for _ in range(len_mask1)])\n",
    "Xtr = np.vstack((Xmask0[0:len_mask1], Xmask1))\n",
    "Ytr = np.concatenate((zeros, ones))\n",
    "                   \n",
    "Xtr,Ytr = ml.shuffleData(Xtr,Ytr)\n",
    "    \n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Select features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47592, 10)\n",
      "(100000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# {A:0, B:0, C:2, D:3, E:4, F:5, G:6, H:7, I:8, J:9, K:10, L:11, M:12, N:13}\n",
    "\n",
    "del_features = [4,6,7,10]\n",
    "# del_features = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "# del_features = [1,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "Xtr = np.delete(Xtr, del_features, axis = 1)\n",
    "Xva = np.delete(Xva, del_features, axis = 1)\n",
    "\n",
    "Xtest = np.delete(Xtest, del_features, axis = 1)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Output Yva to a file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"predictions_five/Y_validation.csv\", \"w\")\n",
    "for y in Yva:\n",
    "    f.write(str(y) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">AdaBoost Decision Trees</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=0.1, n_estimators=1000, random_state=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_dt = sklearn.ensemble.AdaBoostClassifier(sklearn.tree.DecisionTreeClassifier(max_depth=3, max_features=7),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=1000,\n",
    "                         learning_rate=.1)\n",
    "\n",
    "ada_dt.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Scoring</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.75106\n",
      "0.8064658267064289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83     32963\n",
      "         1.0       0.75      0.41      0.53     17037\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     50000\n",
      "   macro avg       0.75      0.67      0.68     50000\n",
      "weighted avg       0.75      0.75      0.73     50000\n",
      "\n",
      "validation\n",
      "0.71032\n",
      "0.7141545029274552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     32915\n",
      "         1.0       0.64      0.35      0.45     17085\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     50000\n",
      "   macro avg       0.68      0.62      0.63     50000\n",
      "weighted avg       0.70      0.71      0.68     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(ada_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"adaboost_dt\", ada_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Adaboost Boost Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "          learning_rate=0.1, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = sklearn.ensemble.AdaBoostClassifier(sklearn.naive_bayes.GaussianNB(),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=100,\n",
    "                         learning_rate=.1)\n",
    "\n",
    "nb.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.68642\n",
      "0.6407541759719991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.92      0.80     32963\n",
      "         1.0       0.61      0.23      0.33     17037\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     50000\n",
      "   macro avg       0.65      0.58      0.56     50000\n",
      "weighted avg       0.67      0.69      0.64     50000\n",
      "\n",
      "validation\n",
      "0.68376\n",
      "0.6387787843671617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.92      0.79     32915\n",
      "         1.0       0.60      0.22      0.32     17085\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     50000\n",
      "   macro avg       0.65      0.57      0.56     50000\n",
      "weighted avg       0.66      0.68      0.63     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"adaboost_nb\", nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Bagged Trees</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedTree(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        \"\"\"Constructs a BaggedTree class with a set of learners. \"\"\"\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self, X):\n",
    "        \"\"\"Predicts the probabilities with each bagged learner and average over the results. \"\"\"\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predictSoft(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predictSoft(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bags = 100\n",
    "bags = []\n",
    "for i in range(n_bags):\n",
    "#   print(\"bag: \" + str(i))\n",
    "  Xi, Yi = ml.bootstrapData(Xtr, Ytr, Xtr.shape[0])\n",
    "  tree = ml.dtree.treeClassify(Xi,Yi,minParent=2**6,maxDepth=15,nFeatures=12)\n",
    "  bags.append(tree)\n",
    "    \n",
    "bt = BaggedTree(bags)\n",
    "bt.classes = np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Train AUC: 0.8642\n",
      " Validation AUC: 0.7215\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC', bt.auc(Xtr, Ytr)))\n",
    "print(\"{0:>15}: {1:.4f}\".format('Validation AUC', bt.auc(Xva, Yva)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytr_hat = bt.predictSoft(Xtr)\n",
    "\n",
    "# Xte = np.genfromtxt('data/X_test.txt',delimiter=None)\n",
    "Ytr_hat = bt.predictSoft(Xtr)\n",
    "f1 = open('predictions_five/baggedtree_tr.txt', 'w')\n",
    "for i in range(len(Ytr_hat)):\n",
    "  temp = Ytr_hat[i]\n",
    "  f1.write(str(temp[1]) + '\\n')\n",
    "f1.close()\n",
    "\n",
    "Ytr_hat = bt.predictSoft(Xva)\n",
    "f1 = open('predictions_five/baggedtree_va.txt', 'w')\n",
    "for i in range(len(Ytr_hat)):\n",
    "  temp = Ytr_hat[i]\n",
    "  f1.write(str(temp[1]) + '\\n')\n",
    "f1.close()\n",
    "\n",
    "Ytr_hat = bt.predictSoft(Xtest)\n",
    "f1 = open('predictions_five/baggedtree_te.txt', 'w')\n",
    "for i in range(len(Ytr_hat)):\n",
    "  temp = Ytr_hat[i]\n",
    "  f1.write(str(temp[1]) + '\\n')\n",
    "f1.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Gradient Boost Decision Trees</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2485           33.69s\n",
      "         2           1.2179           35.52s\n",
      "         3           1.1915           34.51s\n",
      "         4           1.1680           34.27s\n",
      "         5           1.1464           33.98s\n",
      "         6           1.1276           33.65s\n",
      "         7           1.1111           32.73s\n",
      "         8           1.0960           32.02s\n",
      "         9           1.0835           31.69s\n",
      "        10           1.0713           30.74s\n",
      "        20           0.9759           23.06s\n",
      "        30           0.9193           14.44s\n",
      "        40           0.8782            6.65s\n",
      "        50           0.8430            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=10,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_dt = sklearn.ensemble.GradientBoostingClassifier(\n",
    "                         n_estimators=50,\n",
    "                         learning_rate=.1,\n",
    "                         max_depth=10,\n",
    "                         verbose=1)\n",
    "\n",
    "gb_dt.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.82796\n",
      "0.9148625175337015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.97      0.88     32963\n",
      "         1.0       0.91      0.55      0.69     17037\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     50000\n",
      "   macro avg       0.86      0.76      0.78     50000\n",
      "weighted avg       0.84      0.83      0.82     50000\n",
      "\n",
      "validation\n",
      "0.71574\n",
      "0.7281620278303063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.81     32915\n",
      "         1.0       0.65      0.36      0.46     17085\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     50000\n",
      "   macro avg       0.69      0.63      0.63     50000\n",
      "weighted avg       0.70      0.72      0.69     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(gb_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"gradientboost_dt\", gb_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Neural Network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 150, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=50, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(200,150,100), activation=\"relu\", solver=\"adam\", \n",
    "                                            learning_rate_init=0.001, max_iter=50, warm_start=True)\n",
    "nnet.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.70654\n",
      "0.7007307703821006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.93      0.81     32963\n",
      "         1.0       0.67      0.28      0.39     17037\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     50000\n",
      "   macro avg       0.69      0.60      0.60     50000\n",
      "weighted avg       0.70      0.71      0.67     50000\n",
      "\n",
      "validation\n",
      "0.70426\n",
      "0.6956112602093945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.93      0.80     32915\n",
      "         1.0       0.66      0.27      0.39     17085\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     50000\n",
      "   macro avg       0.69      0.60      0.60     50000\n",
      "weighted avg       0.69      0.70      0.66     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"nnet\", nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">KNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 50, weights=\"distance\")\n",
    "knn.fit(Xtr, Ytr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.97658\n",
      "0.9675478355692156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98     32963\n",
      "         1.0       0.99      0.94      0.96     17037\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     50000\n",
      "   macro avg       0.98      0.97      0.97     50000\n",
      "weighted avg       0.98      0.98      0.98     50000\n",
      "\n",
      "validation\n",
      "0.70204\n",
      "0.6099154929928103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.90      0.80     32915\n",
      "         1.0       0.63      0.32      0.42     17085\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     50000\n",
      "   macro avg       0.67      0.61      0.61     50000\n",
      "weighted avg       0.69      0.70      0.67     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"knn\", knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Random Forest</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=1000, min_samples_leaf=5, oob_score=True, verbose=1)\n",
    "rf.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9598732951440566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.97      0.90     32963\n",
      "         1.0       0.91      0.67      0.77     17037\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     50000\n",
      "   macro avg       0.88      0.82      0.84     50000\n",
      "weighted avg       0.87      0.87      0.86     50000\n",
      "\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   11.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398755727665788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.90      0.81     32915\n",
      "         1.0       0.67      0.38      0.48     17085\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     50000\n",
      "   macro avg       0.70      0.64      0.65     50000\n",
      "weighted avg       0.71      0.72      0.70     50000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:   10.9s finished\n"
     ]
    }
   ],
   "source": [
    "score_learner(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "write_to_file(\"randomforest\", rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">XGBoost decision trees</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Training</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=15, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(n_estimators=200, max_depth=15)\n",
    "xgb.fit(Xtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Testing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "0.94422\n",
      "0.9912708292670929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96     32963\n",
      "         1.0       0.96      0.87      0.91     17037\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     50000\n",
      "   macro avg       0.95      0.93      0.94     50000\n",
      "weighted avg       0.94      0.94      0.94     50000\n",
      "\n",
      "validation\n",
      "0.71668\n",
      "0.7368386250072296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.86      0.80     32915\n",
      "         1.0       0.62      0.45      0.52     17085\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     50000\n",
      "   macro avg       0.68      0.65      0.66     50000\n",
      "weighted avg       0.70      0.72      0.70     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_learner(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Output</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(\"xgboost_dt\", xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"10\">Ensemble Predictions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Testing average predictions and majority vote with different weights for each class</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: .7314\n",
    "\n",
    "classifiers = [\n",
    "    [ada_dt, 0],\n",
    "    [nb, 1],\n",
    "    [bt, 0],\n",
    "    [gb_dt, 6],\n",
    "    [nnet, 0],\n",
    "    [knn, 0],\n",
    "    [rf, 5],\n",
    "    [xgb, 5],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    [ada_dt, 0],\n",
    "    [nb, 1],\n",
    "    [bt, 0],\n",
    "    [gb_dt, 6],\n",
    "    [nnet, 0],\n",
    "    [knn, 0],\n",
    "    [rf, 5],\n",
    "    [xgb, 5],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Test ensemble accuracy on validation data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "0.703\n",
      "testing: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "0.68376\n",
      "testing: <class '__main__.BaggedTree'>\n",
      "0.7135\n",
      "testing: <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "0.71574\n",
      "testing: <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "0.70204\n",
      "testing: <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "0.70426\n",
      "testing: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723\n",
      "testing: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "0.71668\n"
     ]
    }
   ],
   "source": [
    "predicts = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(\"testing: \" + str(type(classifier[0])))\n",
    "    if classifier[0] == bt:\n",
    "        predict = BaggedTree.predict_proba(classifier[0], Xva)\n",
    "    else:\n",
    "        predict = classifier[0].predict_proba(Xva)\n",
    "    predict_binary = []\n",
    "    for p in predict:\n",
    "        if p[0] >= .5:\n",
    "            predict_binary.append(0)\n",
    "        else:\n",
    "            predict_binary.append(1)\n",
    "    print(sklearn.metrics.accuracy_score(Yva, predict_binary))\n",
    "    predicts.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [[] for _ in range(len(Xva))]\n",
    "for i in range(len(Xva)):\n",
    "    for j in range(len(classifiers)):\n",
    "        for _ in range(classifiers[j][1]):\n",
    "            result[i].append(predicts[j][i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7)\n",
      "(50000,)\n",
      "0.72022\n",
      "0.7387395456526377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.89      0.81     32915\n",
      "         1.0       0.65      0.39      0.48     17085\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     50000\n",
      "   macro avg       0.70      0.64      0.65     50000\n",
      "weighted avg       0.71      0.72      0.70     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.array(result).shape)\n",
    "\n",
    "means = np.mean(result, axis=1)\n",
    "print(means.shape)\n",
    "\n",
    "means_categorical = []\n",
    "for i in range(len(means)):\n",
    "    means_categorical.append(round(means[i]))\n",
    "\n",
    "# print(sklearn.metrics.accuracy_score(Yva, bt.predict(Xva)))\n",
    "print(sklearn.metrics.accuracy_score(Yva, means_categorical))\n",
    "print(sklearn.metrics.roc_auc_score(Yva, means))\n",
    "print(classification_report(Yva, means_categorical))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Get predictions on test data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "testing: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "testing: <class '__main__.BaggedTree'>\n",
      "testing: <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "testing: <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "testing: <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "testing: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing: <class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    }
   ],
   "source": [
    "test_predicts = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(\"testing: \" + str(type(classifier[0])))\n",
    "    if classifier[0] == bt:\n",
    "        predict = BaggedTree.predict_proba(classifier[0], Xtest)\n",
    "    else:\n",
    "        predict = classifier[0].predict_proba(Xtest)\n",
    "    test_predicts.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_predicts).shape)\n",
    "result = [[] for _ in range(len(Xtest))]\n",
    "for i in range(len(Xtest)):\n",
    "    for j in range(len(classifiers)):\n",
    "        for _ in range(classifiers[j][1]):\n",
    "            result[i].append(test_predicts[j][i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 7)\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(result).shape)\n",
    "\n",
    "means = np.mean(result, axis=1)\n",
    "print(means.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predictions to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2)\n"
     ]
    }
   ],
   "source": [
    "# f = open(\"predictions_four/kaggle_submit_2.txt\", \"w\")\n",
    "# f.write(\"ID,prob1\\n\")\n",
    "# for i in range(len(means)):\n",
    "#     f.write(str(i) + \", \" + str(round(means[i],2)) + \"\\n\")\n",
    "# f.close()\n",
    "\n",
    "Yte = np.vstack((np.arange(means.shape[0]), means)).T\n",
    "print(Yte.shape)\n",
    "np.savetxt('predictions_five/Y_submit.txt',Yte,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Testing majority predictions on validaiton data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71856\n",
      "0.6194368828356897\n"
     ]
    }
   ],
   "source": [
    "classifiers = [ada_dt, bt, gb_dt, knn, nnet, rf, xgb]\n",
    "majority_predict = []\n",
    "for i in range(len(predicts[0])):\n",
    "    num_zero = 0\n",
    "    for j in range(len(predicts)):\n",
    "        if predicts[j][i][1] <= 0.5:\n",
    "            num_zero += 1\n",
    "    if num_zero > len(classifiers) / 2:\n",
    "        majority_predict.append(0)\n",
    "    else:\n",
    "        majority_predict.append(1)\n",
    "        \n",
    "print(sklearn.metrics.accuracy_score(Yva, majority_predict))\n",
    "print(sklearn.metrics.roc_auc_score(Yva, majority_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.93      0.81     32915\n",
      "         1.0       0.70      0.31      0.43     17085\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     50000\n",
      "   macro avg       0.71      0.62      0.62     50000\n",
      "weighted avg       0.71      0.72      0.68     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Yva, majority_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write majority vote predictions to a file, did not end up using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [ada_dt, bt, gb_dt, knn, nnet, rf, xgb]\n",
    "majority_predict = []\n",
    "for i in range(len(test_predicts[0])):\n",
    "    num_zero = 0\n",
    "    for j in range(len(test_predicts)):\n",
    "        if test_predicts[j][i][1] <= 0.5:\n",
    "            num_zero += 1\n",
    "    if num_zero > len(classifiers) / 2:\n",
    "        majority_predict.append(0)\n",
    "    else:\n",
    "        majority_predict.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81137\n"
     ]
    }
   ],
   "source": [
    "num_zero = 0\n",
    "for p in majority_predict:\n",
    "    if p == 0:\n",
    "        num_zero += 1\n",
    "print(num_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"predictions_five/kaggle_submit_majority_vote.txt\", \"w\")\n",
    "f.write(\"ID,prob1\\n\")\n",
    "for i in range(len(majority_predict)):\n",
    "    f.write(str(i) + \", \" + str(round(majority_predict[i],2)) + \".0\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
